# 📋 讨论结果

## 目标描述
**背景**：用户需要一个播客处理workflow，能够将播客转换为可交互的文字稿网站
**需求**：
1. 获取播客URL的文字稿，并区分说话人
2. 将文字稿可视化成可交互网站，支持快速浏览对话
3. 自动根据shownotes分块（trunk），用户可选择特定片段浏览
4. 形成稳定skill，以后输入播客URL就能得到可视化网站
**约束**：
- 频繁使用，个人使用
- 倾向Python技术栈
- 初始阶段先做YouTube MVP，验证后再扩展其他平台

## 解法说明

### 阶段1：YouTube Pipeline（核心功能）

#### 模块1：YouTube内容获取
- 使用 `yt-dlp` 下载音频（MP3格式）或视频
- 提取视频描述（包含可能的timeline）
- 提取视频标题、频道信息等元数据
- 输出：音频文件 + 元数据JSON

#### 模块2：语音识别 + 说话人分离
- 语音识别：OpenAI Whisper (medium模型，平衡速度和准确性)
- 说话人分离：`pyannote.audio`（需要Hugging Face token）
- 处理流程：
  1. Whisper转文字 → 带时间戳的文字稿
  2. pyannote分离说话人 → 带时间戳的说话人标签
  3. 合并 → `{"start": 0, "end": 5, "speaker": "SPEAKER_00", "text": "..."}`
- 分段：长视频每10分钟一段处理

#### 模块3：Shownotes提取和Timeline解析
- 从YouTube视频描述中获取完整文本
- 正则匹配timeline：`(\d{1,2}):(\d{2})` 或 `(\d{1,2}):(\d{2}):(\d{2})`
- 输出：`[{"start": 0, "end": 300, "topic": "开场介绍"}, ...]`

#### 模块4：智能分块
- 优先级1：使用解析出的作者timeline
- 优先级2：如果没有timeline，使用语义分割
  - 简单方案：基于话题关键词聚类
  - 进阶方案：用轻量级LLM（如GPT-4o-mini）分析文字稿
- 输出：分块后的文字稿，每块包含时间范围、话题、对话内容

#### 模块5：交互式网站
- 后端：FastAPI（Python）
- 前端：Streamlit 或 纯HTML+JS（更轻量）
- 功能：
  - 显示分块列表（可点击跳转）
  - 显示选中块的详细对话（区分说话人，不同颜色）
  - 音频播放器 + 高亮当前播放位置
  - 搜索功能（搜索关键词）
- 部署：本地运行 `python app.py` → 自动打开浏览器

#### 模块6：Skill封装
- CLI命令：`podcast-visualize <youtube_url>`
- 工作流：下载 → 识别 → 分块 → 启动网站
- 网站启动后显示 `http://localhost:8501`
- 缓存机制：已处理的视频缓存音频+文字稿，避免重复处理

### 阶段2：扩展到其他平台（未来）
- 复用模块2、模块4、模块5
- 只需新增模块1（平台特定获取逻辑）
- 预计扩展难度：每个平台1-2小时

## 注意事项
- pyannote.audio需要Hugging Face token和用户协议接受
- 长播客需要分段处理，避免内存问题
- 网站初始本地部署，未来可考虑云端部署
- 优先实现核心功能，细节可迭代优化
