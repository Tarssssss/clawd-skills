"""
YouTubeä¸‹è½½æ¨¡å—
ä½¿ç”¨yt-dlpä¸‹è½½éŸ³é¢‘å’Œæå–å…ƒæ•°æ®
"""

import os
import json
import re
from typing import Dict, Optional
import yt_dlp


def extract_video_id(url: str) -> Optional[str]:
    """ä»YouTube URLä¸­æå–video ID"""
    patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)',
        r'(?:youtube\.com\/watch\?.*v=)([^&\n?#]+)'
    ]

    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)

    return None


class YouTubeDownloader:
    """YouTubeä¸‹è½½å™¨"""

    def __init__(self, cache_dir: str = "./cache", cookies_path: str = None):
        self.cache_dir = cache_dir
        self.cookies_path = cookies_path
        os.makedirs(cache_dir, exist_ok=True)

    def download_audio(self, url: str, skip_cache: bool = False) -> Dict:
        """
        ä¸‹è½½YouTubeéŸ³é¢‘

        Args:
            url: YouTubeè§†é¢‘URL
            skip_cache: æ˜¯å¦è·³è¿‡ç¼“å­˜

        Returns:
            åŒ…å«éŸ³é¢‘è·¯å¾„å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        video_id = extract_video_id(url)
        if not video_id:
            raise ValueError(f"æ— æ³•ä»URLä¸­æå–video ID: {url}")

        audio_path = os.path.join(self.cache_dir, f"{video_id}.mp3")
        metadata_path = os.path.join(self.cache_dir, f"{video_id}.metadata.json")

        # æ£€æŸ¥ç¼“å­˜
        if not skip_cache and os.path.exists(audio_path) and os.path.exists(metadata_path):
            print(f"âœ“ ä½¿ç”¨ç¼“å­˜: {video_id}")
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            return {
                "audio_path": audio_path,
                "metadata": metadata,
                "video_id": video_id,
            }

        # ä¸‹è½½é…ç½®
        ydl_opts = {
            'format': 'bestaudio/best',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'outtmpl': os.path.join(self.cache_dir, f'{video_id}.%(ext)s'),
            'quiet': False,
            'no_warnings': False,
            # é¢å¤–å‚æ•°å°è¯•ç»•è¿‡æœºå™¨äººæ£€æµ‹
            'nocheckcertificate': True,
            'ignoreerrors': False,
            'no_warnings': False,
        }

        # æ·»åŠ cookiesï¼ˆå¦‚æœæä¾›ï¼‰
        if self.cookies_path:
            ydl_opts['cookiefile'] = self.cookies_path
            print(f"ğŸª ä½¿ç”¨cookies: {self.cookies_path}")
            # æ‰“å°ä¸€äº›cookieä¿¡æ¯ç”¨äºè°ƒè¯•
            if os.path.exists(self.cookies_path):
                with open(self.cookies_path, 'r') as f:
                    lines = f.readlines()
                    # è¿‡æ»¤æ‰æ³¨é‡Šå’Œç©ºè¡Œ
                    cookie_lines = [line for line in lines if line.strip() and not line.strip().startswith('#')]
                    print(f"  æ‰¾åˆ° {len(cookie_lines)} ä¸ªcookies")

        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½: {url}")
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)

        # æå–å…ƒæ•°æ®
        metadata = {
            "title": info.get('title', ''),
            "description": info.get('description', ''),
            "uploader": info.get('uploader', ''),
            "duration": info.get('duration', 0),
            "upload_date": info.get('upload_date', ''),
            "view_count": info.get('view_count', 0),
            "video_id": video_id,
            "url": url,
        }

        # ä¿å­˜å…ƒæ•°æ®
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"âœ“ ä¸‹è½½å®Œæˆ: {metadata['title']}")
        print(f"  æ—¶é•¿: {metadata['duration']}ç§’")

        return {
            "audio_path": audio_path,
            "metadata": metadata,
            "video_id": video_id,
        }
